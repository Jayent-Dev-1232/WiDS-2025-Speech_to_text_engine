{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444ed703",
   "metadata": {},
   "source": [
    "# ***Solution of Coding Tasks***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9206cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, log_loss, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f090c2d",
   "metadata": {},
   "source": [
    "## ***Task-1*** : Implementing Tokenization and Stemming using Python + NLTK/spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2da230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Loading the IMDb dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1e26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataset to pandas DataFrame\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "test_df = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# Saving the DataFrames to CSV files\n",
    "train_df.to_csv(\"imdb_train.csv\", index=False)\n",
    "test_df.to_csv(\"imdb_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bd0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 25000\n",
      "Total testing samples: 25000\n"
     ]
    }
   ],
   "source": [
    "corpus_train = train_df['text'].values\n",
    "labels_train = train_df['label'].values\n",
    "corpus_test = test_df['text'].values\n",
    "labels_test = test_df['label'].values\n",
    "print(\"Total training samples:\", len(corpus_train))\n",
    "print(\"Total testing samples:\", len(corpus_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979c7cb",
   "metadata": {},
   "source": [
    "##### ***Text Pre-processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e0bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the corpus\n",
    "corpus_train_lower = []\n",
    "corpus_test_lower = []\n",
    "for i in range(len(corpus_train)):\n",
    "    corpus_train_lower.append(corpus_train[i].lower())\n",
    "for i in range(len(corpus_test)):\n",
    "    corpus_test_lower.append(corpus_test[i].lower())\n",
    "\n",
    "# Adding the Lowercased text column to the DataFrame\n",
    "train_df[\"Lowercase Text\"] = corpus_train_lower\n",
    "test_df[\"Lowercase Text\"] = corpus_test_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfaf563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations, special characters, HTML tags, URLs, and extra spaces from the corpus\n",
    "corpus_train_cleaned = []\n",
    "corpus_test_cleaned = []\n",
    "for i in range(len(corpus_train_lower)):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', re.sub(r'[^\\w\\s]', '', re.sub(r'<.*?>', '', re.sub(r'http\\S+|www\\.\\S+', '', corpus_train_lower[i])) )).strip()\n",
    "    corpus_train_cleaned.append(cleaned_text)\n",
    "for i in range(len(corpus_test_lower)):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', re.sub(r'[^\\w\\s]', '', re.sub(r'<.*?>', '', re.sub(r'http\\S+|www\\.\\S+', '', corpus_test_lower[i])) )).strip()\n",
    "    corpus_test_cleaned.append(cleaned_text)\n",
    "\n",
    "# Adding the Cleaned text column to the DataFrame\n",
    "train_df[\"Cleaned Text\"] = corpus_train_cleaned\n",
    "test_df[\"Cleaned Text\"] = corpus_test_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4882a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of the cleaned corpus\n",
    "tokenizer = word_tokenize\n",
    "corpus_train_tokenized = []\n",
    "corpus_test_tokenized = []\n",
    "for i in range(len(corpus_train_cleaned)):\n",
    "    tokens = tokenizer(corpus_train_cleaned[i])\n",
    "    corpus_train_tokenized.append(tokens)\n",
    "for i in range(len(corpus_test_cleaned)):\n",
    "    tokens = tokenizer(corpus_test_cleaned[i])\n",
    "    corpus_test_tokenized.append(tokens)\n",
    "\n",
    "# Adding the Tokenized text column to the DataFrame\n",
    "train_df[\"Tokenized Text\"] = corpus_train_tokenized\n",
    "test_df[\"Tokenized Text\"] = corpus_test_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26d3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from the tokenized corpus\n",
    "stop_words = set(stopwords.words('english'))\n",
    "corpus_train_no_stopwords = []\n",
    "corpus_test_no_stopwords = []\n",
    "for tokens in corpus_train_tokenized:\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    corpus_train_no_stopwords.append(filtered_tokens)\n",
    "for tokens in corpus_test_tokenized:\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    corpus_test_no_stopwords.append(filtered_tokens)\n",
    "\n",
    "# Adding the No Stopwords text column to the DataFrame\n",
    "train_df[\"No Stopwords Text\"] = corpus_train_no_stopwords\n",
    "test_df[\"No Stopwords Text\"] = corpus_test_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d8ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "corpus_train_stemmed = []\n",
    "corpus_test_stemmed = []\n",
    "for i in range(len(corpus_train_no_stopwords)):\n",
    "    stemmed_tokens = stemmer.stem(' '.join(corpus_train_no_stopwords[i]))\n",
    "    corpus_train_stemmed.append(stemmed_tokens)\n",
    "for i in range(len(corpus_test_no_stopwords)):\n",
    "    stemmed_tokens = stemmer.stem(' '.join(corpus_test_no_stopwords[i]))\n",
    "    corpus_test_stemmed.append(stemmed_tokens)\n",
    "\n",
    "# Adding the Stemmed text column to the DataFrame\n",
    "train_df[\"Stemmed Text\"] = corpus_train_stemmed\n",
    "test_df[\"Stemmed Text\"] = corpus_test_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb03f3",
   "metadata": {},
   "source": [
    "## ***Task-2*** : Build a TF-IDF text classifier for sentiment(IMDb or SST-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd42954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train_df[\"Stemmed Text\"])\n",
    "X_test  = tfidf.transform(test_df[\"Stemmed Text\"])\n",
    "\n",
    "y_train = train_df[\"label\"].values\n",
    "y_test  = test_df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41bc488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python 3.11.9\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "\n",
    "    \"Softmax Regression\": LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000\n",
    "    ),\n",
    "\n",
    "    \"Naive Bayes\": MultinomialNB(alpha=1.0),\n",
    "\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "\n",
    "    \"SGD Classifier\": SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        max_iter=1000,\n",
    "        tol=1e-3\n",
    "    ),\n",
    "\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e5ca903",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = SmoothingFunction().method1\n",
    "results = {}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = None\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"mcc\": matthews_corrcoef(y_test, y_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    if y_prob is not None:\n",
    "        metrics[\"roc_auc\"] = roc_auc_score(y_test, y_prob)\n",
    "        metrics[\"log_loss\"] = log_loss(y_test, y_prob)\n",
    "    else:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "        metrics[\"log_loss\"] = None\n",
    "\n",
    "    bleu_scores = [\n",
    "        sentence_bleu([[str(t)]], [str(p)], smoothing_function=smooth)\n",
    "        for t, p in zip(y_test, y_pred)\n",
    "    ]\n",
    "    metrics[\"bleu\"] = np.mean(bleu_scores)\n",
    "\n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2fc7558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "accuracy: 0.88748\n",
      "precision: 0.8861516383640278\n",
      "recall: 0.8892\n",
      "f1: 0.8876732020924011\n",
      "mcc: 0.7749645853240237\n",
      "confusion_matrix: [[11072  1428]\n",
      " [ 1385 11115]]\n",
      "roc_auc: 0.9550505471999999\n",
      "log_loss: 0.3269663409204867\n",
      "bleu: 0.15781874108213434\n",
      "\n",
      "Softmax Regression\n",
      "accuracy: 0.88968\n",
      "precision: 0.8910565189466924\n",
      "recall: 0.88792\n",
      "f1: 0.8894854944702677\n",
      "mcc: 0.7793648283359408\n",
      "confusion_matrix: [[11143  1357]\n",
      " [ 1401 11099]]\n",
      "roc_auc: 0.9568329471999999\n",
      "log_loss: 0.29847753838544466\n",
      "bleu: 0.1582099625523429\n",
      "\n",
      "Naive Bayes\n",
      "accuracy: 0.86064\n",
      "precision: 0.8780610533378062\n",
      "recall: 0.8376\n",
      "f1: 0.857353422862758\n",
      "mcc: 0.7220469925294833\n",
      "confusion_matrix: [[11046  1454]\n",
      " [ 2030 10470]]\n",
      "roc_auc: 0.9354395520000001\n",
      "log_loss: 0.378983809489333\n",
      "bleu: 0.15304583914558986\n",
      "\n",
      "Linear SVM\n",
      "accuracy: 0.88296\n",
      "precision: 0.8903930843255586\n",
      "recall: 0.87344\n",
      "f1: 0.881835069865116\n",
      "mcc: 0.7660588690303443\n",
      "confusion_matrix: [[11156  1344]\n",
      " [ 1582 10918]]\n",
      "roc_auc: None\n",
      "log_loss: None\n",
      "bleu: 0.15701495878879673\n",
      "\n",
      "Ridge Classifier\n",
      "accuracy: 0.882\n",
      "precision: 0.8874553716325868\n",
      "recall: 0.87496\n",
      "f1: 0.8811633902674831\n",
      "mcc: 0.764075741386579\n",
      "confusion_matrix: [[11113  1387]\n",
      " [ 1563 10937]]\n",
      "roc_auc: None\n",
      "log_loss: None\n",
      "bleu: 0.156844243965433\n",
      "\n",
      "SGD Classifier\n",
      "accuracy: 0.88032\n",
      "precision: 0.8780216284987278\n",
      "recall: 0.88336\n",
      "f1: 0.880682724517467\n",
      "mcc: 0.7606540594510447\n",
      "confusion_matrix: [[10966  1534]\n",
      " [ 1458 11042]]\n",
      "roc_auc: 0.9499995456\n",
      "log_loss: 0.3813130161971733\n",
      "bleu: 0.15654549302454646\n",
      "\n",
      "Random Forest\n",
      "accuracy: 0.8582\n",
      "precision: 0.8682457438934122\n",
      "recall: 0.84456\n",
      "f1: 0.8562391013423091\n",
      "mcc: 0.7166667207459801\n",
      "confusion_matrix: [[10898  1602]\n",
      " [ 1943 10557]]\n",
      "roc_auc: 0.9342212160000001\n",
      "log_loss: 0.45312279450522636\n",
      "bleu: 0.15261193896954037\n",
      "\n",
      "Gradient Boosting\n",
      "accuracy: 0.8086\n",
      "precision: 0.7768209544312881\n",
      "recall: 0.866\n",
      "f1: 0.8189899754113863\n",
      "mcc: 0.621307698271028\n",
      "confusion_matrix: [[ 9390  3110]\n",
      " [ 1675 10825]]\n",
      "roc_auc: 0.8949861664\n",
      "log_loss: 0.45525078489088505\n",
      "bleu: 0.1437916730957473\n",
      "\n",
      "BEST MODEL BASED ON F1: Softmax Regression\n"
     ]
    }
   ],
   "source": [
    "for model, metrics in results.items():\n",
    "    print(f\"\\n{model}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "best_model_name = max(results, key=lambda x: results[x][\"f1\"])\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(\"\\nBEST MODEL BASED ON F1:\", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10fb5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(texts):\n",
    "    X = tfidf.transform(texts)\n",
    "    return best_model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
